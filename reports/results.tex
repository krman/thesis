\chapter{Results}

This chapter presents the results of the analysis performed using the framework.It is divided into two parts: the first presents a comparison of the performance of the three routing metrics, in terms of overall resulting throughput in the network; the second discusses how well each metric would scale to larger topologies than it is possible to use in these experiments.

\section{Comparison of Routing Metrics}
POINTS

hard to distinguish efficient routing metrics on small topologies like pentagon

apparently performs well as flows approach 

limited to 9 Mbps flows
needed to increase offered load, so switched to flow pattern random
RC performance tails off dramatically
unclear why
suspect that it is because the module is unable to find an optimal solution
though there is some variation due to the random the effect is consistent across 15 trials, taken in three blocks of 5 at different times
unclear whether it is significant that flows drop off around 80?


\begin{landscape}
\begin{figure}
\centering
\input{figures/bidirectional}
\caption{Aggregate throughput comparison for flow pattern `bidirectional'}
Each mark represents the mean of 10 trials for that load/topology combination.
\label{fig:pairs}
\end{figure}

\begin{figure}
\centering
\input{figures/resultspairs}
\caption{Aggregate throughput comparison for flow pattern `pairs'}
\label{fig:pairs}
Each mark represents the mean of 10 trials for that load/topology combination.
\end{figure}

\begin{figure}
\centering
\input{figures/resultsrandom}
\caption{Aggregate throughput comparison for flow pattern `random'}
Each mark represents the mean of 15 trials for that load/topology combination.
\label{fig:random}
\end{figure}
\end{landscape}

\section{Scalability of Objective Functions}

\begin{figure}
\centering
\input{figures/scalability1}
\caption{Comparison of routing algorithm scalability}
\label{fig:sca1}
Computation time is the time taken to route 16 random flows in Al-Fares fat-tree networks with increasing parameter $k$. Error bars show 95\% confidence intervals but are too small to be visible for the shortest path and widest path metrics. 
\end{figure}

From the perspective of the experiments in this thesis, where the largest network considered was an Al-Fares fat-tree with k=4, the time taken to calculate routes is negligible for all routing metrics.

However, in general an important consideration when selecting a routing metric is the computation time required to calculate routes for all flows in the network. This is particularly important if the objective function is to be rerun every few seconds in order to ensure optimal paths are being used. It is therefore desirable to know how well the objective function scales to larger networks.

Running experiments on Mininet means that there are practical limitations of the system, chiefly availability of RAM, which limit the size of networks which can be emulated with Mininet; this limit is hit long before the scalability of objective functions becomes a factor. However, it is possible to test the scalability of individual objective functions without the surrounding framework, by passing mock network graphs and flow statistics to the function. 

The Al-Fares fat-tree is parametrisable by a parameter $k$, which indicates the number of ports per commodity switch used in the network; this produces a network with $(k/2)^2+k^2$ switches and $k^3/4$ hosts in total, and is therefore easy to scale up to large networks for scalability testing. In this test, flows were randomly generated between 16 random hosts, for Al-Fares networks starting from k = 4 until further tests became impractically slow to run (greater than 5 seconds).  The results of this testing are shown in Figure \ref{fig:sca1}, for each of the three routing metrics.

As expected, the shortest-path metric scales extremely well. The basic algorithm is well-understood, and the particular implementation used here is the one provided with NetworkX, which includes a number of small optimisations as well.

The residual spare capacity implementation is based on the formulation described originally by Walkowiak \cite{walkowiak:residual}. As seen in section \ref{sec:rc}, the performance of the algorithm as a whole depends mostly on the number of possible paths in the network. In its original form, the solution becomes unworkably slow at $k = 6$, with just 45 switches considered. One major optimisation was therefore implemented: the length of possible paths considered is limited to 6 hops. This is enough hops to allow multiple paths to each aggregation and core switch, but not to bounce indefinitely and unnecessarily between the core, aggregation and edge layers. Figure \ref{fig:sca2} demonstrates how much the scalability of the residual capacity metric is dependent on the maximum path length considered.

\begin{figure}
\centering
\input{figures/scalability2}
\caption{Effect of maximum path length for residual capacity metric}
\label{fig:sca2}
Computation time is as for Figure \ref{fig:sca1}. Instead of considering all possible paths between hosts, only consider paths with a maximum path length of $n$ hops.
\end{figure}

The widest path metric performs quite poorly for such a well-known routing metric. The algorithm is based on a modified Dijkstra's algorithm, as described in section \ref{sec:wp}, which is not known to be particularly inefficient; the poor performance of the metric in these experiments is likely to be due to poor implementation. In particular, the algorithm must consider every path in the network, so, as for the residual capacity metric, the number of paths in an Al-Fares fat-tree can be very high and this is likely to be a significant factor in the algorithm's scalability. Unlike for residual capacity, however, limiting the number of paths considered was non-trivial due to the particular implementation, so this optimisation was not implemented. However, the dramatic effect of path length on the residual capacity metric seems to indicate that this could provide better scalability in this similar metric as well.

In general, it seems that the approach used in this thesis would be reasonable: route flows initially along the shortest path, then every few seconds, recalculate globally-optimal routes. In a normal scenario, however, the routing recalculation is performed every few seconds, and it is likely that many flows would be similar between calculations. This assumption can be made stronger if flows are consolidated; for example, group `all HTTP traffic' along similar paths instead of calculating flow rules for individual flows, increasing the likelihood that the grouped flow will still be present in the future.

In many optimisation techniques, such as branch-and-bound (used in this work by GLPK \cite{glpk}) and simulated annealing (used in \cite{alfares:hedera}), starting from an estimated solution which is close to the optimum greatly decreases the time taken to reach optimal levels. Here, the previous route allocation could be used as such an estimated solution. However, the implementation of this is non-trivial, and limits the use of third-party interfaces such as PuLP, since there is no way to specify a starting estimate for most solvers. This is far outside the scope of this project and definitely in the realm of `future work'.
