\chapter{Background}
\label{ch:background}

\section{Software-Defined Networking}
Software-defined networking, as described earlier, is a set of philosophies and concepts about network design. Crucially, networking should be programmable. The core idea is separation of the control and data planes; specifically, separation in a way that is standards-compliant and vendor-independent \cite{onf:sdn}. Although the movement is not intrinsically tied to any specific technologies, the OpenFlow protocol \cite{onf:switch140}, which is used to communicate between the control and data planes, is quite strongly linked to it.

McKeown describes the networking industry as vertically integrated and proprietary, with little innovation \cite{mckeown:sdn}, comparing this to the state of computing prior to the adoption of high-level operating systems using standard instruction sets to communicate with the hardware. Similarly, the control plane in SDN can be seen as a network operating system, with OpenFlow as the instruction set for communicating with switches. This echoes the development towards greater abstraction evidenced by the move towards flow- over packet-based networking and the rise of quality-of-service considerations. Such requirements can be difficult to meet without some control over switch forwarding tables.

\begin{figure}
  \centering
  \includegraphics[scale=0.8]{../images/sdnclear.pdf}
  \caption{Centralisation of control in software defined networks}
  Each switch maintains an out-of-band connection to a controller, which instructs switches to update their forwarding tables via the OpenFlow protocol.
  \label{fig:sdn}
\end{figure}

OpenFlow was originally conceived \cite{mckeown:openflow} as a research tool to enable academics to test new protocols easily and receive rapid feedback, while allowing vendors to continue to protect the inner workings of their switches. More recently \cite{onf:sdn} the focus has shifted to large datacenters and commercial networks with complex routing requirements. In \cite{mckeown:sdn}, McKeown refers to the  ``ossified network'': due to the black-box nature of modern network components such as switches and routers, experimentation is not encouraged and researchers and network administrators must stick to standard protocols until new ones are supported by vendors. This process can take a long time and the feedback cycle is slow. In contrast, SDN offers the ability to easily implement new protocols on real networks, and programmatically and automatically test and monitor many more aspects of the system.

Software-defined networks rely on two concepts: flow-based routing and the existence of a central controller. Flow-based routing means routing based on flows (linked series of related packets such as all TCP traffic, all traffic from one MAC address or to a particular IP subnet). This concept was reasonably well-developed \cite{wellons:oblivious,wang:routing} before SDN.

The other element of SDN is the existence of a central network OS which can communicate with all nodes. This raises the obvious objection that in many cases, for example in mesh networks, centralisation is not ideal; however, this is not centralised routing where all packets must pass through the controller. The authors of Aster*x \cite{handigol:asterix} make the distinction between ``logically centralised'' and ``distributed through the network'': once rules are installed, packet forwarding happens at individual switches as usual. The controller can push an initial set of rules as soon as a switch connects to it if desired. Later, when the first packet of a new kind of flow arrives at a switch, it encapsulates the packet and sends it to the controller. The controller then installs the appropriate rules on the appropriate switches \cite{mckeown:sdn}. Depending on configuration (fail standalone mode or fail secure mode) these rules can remain in place if the controller connection is lost, or the switch can drop all packets \cite{onf:switch140}.

\subsection{Examples}
The following SDN projects had a particular influence on some aspect of the design of this thesis and are therefore described in more detail here.

Dely et al \cite{dely:wmn} implemented an SDN controller and tested it on the KAUMesh testbed, using the metrics of forwarding performance, amount of control traffic and rule activation time. The performance was within acceptable limits for their small-scale test, but they noted that scalability could be an issue when deploying on larger networks. The scalability of routing algorithms considered in this thesis is therefore evaluated, in addition to the resulting throughput.

A project that had particular influence on the experimental design in this thesis was the Hedera project \cite{alfares:hedera}, aimed at large-scale enterprise applications. For part of the work, they compared the performance of two routing metrics, global-first-fit and simulated annealing. The paper describes a wide range of traffic flow patterns used to evaluate each metric, some of which where adapted for use in this thesis. Additionally, two of the authors also presented a paper \cite{alfares:fattree} on the fat-tree topology used for their experiments, which was also used in experiments for this thesis.

Several other projects used linear programming to solve a particular problem known as the multicommodity flow problem (MCFP). These attempts are outlined in the following section.

\section{Multicommodity Flow Problems}
\label{sec:mcf}

SDN does not make any judgment on what metric should be used by the controller to allocate flows. Indeed, it is possible to use prewritten modules in controller frameworks such as POX \cite{onl:pox} to emulate traditional routers or simple forwarding switches. However, SDN offers one particular advantage over traditional routing that is of interest here: the ability to easily maintain a global view of the network. The routing problem is then reduced to one which is well-known in graph theory: the multicommodity flow problem.

In the MCFP, flows are modelled as commodities moving between various source and sink nodes in the network \cite[pp. 862--863]{cormen:algorithms}. Each flow has an associated demand, representing the bandwidth consumed by that flow. The approach is mentioned in \cite{wellons:augmenting} and \cite{dai:dynamic}. This is an optimisation problem where the objective function can be adjusted depending on the desired outcomes, such as maximising overall throughput or maximising worst-case performance. The authors of \cite{wellons:augmenting} note that such approaches can be sensitive to accurate predictions of demand, but had success merging it with more dynamic heuristic algorithms.

A subcategory of the multicommodity flow problem which is more relevant to network routing is known as the unsplittable flow problem (UFP), and is also well-studied in the optimisation literature \cite{anag:mazing, bonsma:ufp, chakrabarti:ufp, walkowiak:residual}. The problem is motivated by the effective restriction when routing TCP traffic that all packets should travel along the same path. If multiple paths are taken, this increases the risk that packets will arrive out of order. TCP interprets this as congestion in the network and slows down its sending rate, thereby decreasing the throughput for that flow. The UFP adds the restriction that flows must be routed along exactly one path.

\section{Linear Programming}
Both the MCFP and the UFP are usually expressed as an objective to be maximised or minimised, and a series of constraints. The objective function represents the overall `goal' of the system and can vary by formulation, as different applications warrant a different focus. However, the constraints reflect the limitations imposed by the underlying network and therefore do not significantly vary.

Problems which can be expressed in this way are known as linear programs and can be solved (an optimal solution found, within the bounds of the constraints) using general solvers such as the GNU Linear Programming Kit (GLPK) \cite{glpk}. Most techniques used by such solvers use algorithms using linear algebra, such as the simplex and branch-and-cut methods; however, it is usually not necessary to know the algorithm being used, as interfaces to such solvers often only require a high-level description of objective and constraints and return the combination 
