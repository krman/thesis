\documentclass[pdftex,12pt,a4paper]{article}

\usepackage{fullpage}
\usepackage{setspace}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{framed}
\usepackage[pdftex]{graphicx}
\usepackage{booktabs}
\usepackage{float}
\usepackage{tikz}
\usepackage{tabularx}

\doublespacing
\setlength{\parindent}{1.5cm}

\begin{document}

\thispagestyle{empty}
\begin{center}
	\vspace*{35mm}
	{\huge\bf
		Optimal Mesh Routing \\
		in Software Defined Networks \\
	}

	\vspace{20mm}
	{\Large 
		METR4900 Thesis Proposal \\
	}

	\vspace{20mm}
	Kimberley Manning / 41966350 \\
	Supervisor: Marius Portmann
\end{center}

\newpage
\thispagestyle{empty}
\tableofcontents
\listoftables

\newpage
\pagenumbering{arabic}
\section{Overview}
The goal of this thesis is to implement a central controller to do optimal routing on a wireless mesh network, given the network topology and link information. The controller will be benchmarked against a selection of existing approaches to routing in wireless mesh networks. Reproducible network tests will be performed using the network simulator Mininet; the controller will be implemented using the controller framework POX.

\subsection{Goals}
The project's goals can be summarised as follows:

\begin{enumerate}
	\item Develop a set of topologies and events to use in testing
	\item Benchmark the performance of major approaches to mesh routing
	\item Design, implement and test a new controller in POX
\end{enumerate}

\subsection{Relevance}
Software-defined networking (SDN) is a relatively new concept in networking which aims to give network operators greater programmability and control over their networks, through separation of the control and data planes. The way this is most commonly implemented involves a centralised controller which sends network control packets to other switches on the network, usually on a separate, parallel control network. 

Mesh networks, however, are inherently distributed: this contradicts several key assumptions made in most discussions of SDN about the network architecture, especially for wireless meshes. A centralised, single-point-of-failure controller seems not to meet the requirements of the system, but the other benefits of software-defined control are such that several different groups have attempted to design hybrid controllers which do, to varying degrees and with sometimes limited scope. This thesis will compare these approaches and, using insights from this process, present a new controller.

\newpage
\section{Background}
\subsection{Software-Defined Networking}
Software-defined networking is a set of philosophies and concepts on how networking should be done. Crucially, networking should be programmable. The core idea is separation of the control and data planes; specifically, separation in a way that is standards-compliant and vendor-independent \cite{onf:sdn}. Although the movement is not intrinsically tied to any specific technologies, the OpenFlow protocol \cite{onf:switch140}, which is used to communicate between the control and data planes, is quite strongly linked to it.

McKeown describes the networking industry as vertically integrated and proprietary, with little innovation \cite{mckeown:sdn}, comparing this to the state of computing prior to the adoption of high-level operating systems using standard instruction sets to communicate with the hardware. Similarly, the control plane in SDN can be seen as a network operating system, with OpenFlow as the instruction set for communicating with switches. This echoes the development towards greater abstraction evidenced by the move towards flow- over packet-based networking and the rise of quality-of-service considerations. Such requirements can be difficult to meet without some control switch forwarding tables.

OpenFlow was originally conceived as a research tool to enable academics to test new protocols easily and receive rapid feedback, while allowing vendors to continue to protect the inner workings of their switches. In \cite{mckeown:openflow}, McKeown refers to the  ``ossified network'': due to the black-box nature of modern network components such as switches and routers, experimentation is not encouraged and researchers must stick to standard protocols until new ones are supported by vendors. This process can take a long time and the feedback cycle is slow. 

Focus in the SDN movement has shifted from the original goal of ease of research \cite{mckeown:openflow}, to large datacentres and commercial networks with complex routing requirements. SDN approaches usually make assumptions appropriate for this use case, but in all cases, the primary assumption of a dedicated control plane holds.

\newpage
\subsection{Mesh Networks}
wireless mesh networks are a thing. they are distributed, often over wide geographical area, and are only connected in wireless links. this contradicts certain assumptions about the way sdn is implemented. mesh networks are inherently decentralised with no single point of failure, but most sdn implementations have a central controller. there is no separate control network, so all network control messages must be in-band. any part of the mesh may drop out and hence lose contact with the controller at any point, so fallback needs to be implemented.

on the surface they don't seem very well suited to sdn at all, what with the whole centralised controller thing. need to come up with reasons you would still want to do sdn for wmns. all the other advantages like programmability, automation etc must still apply. note that openflow lets switches be controlled by multiple controllers if necessary, or you can load-balance/fault-tolerance-ise the controllers with something else, or whatever. or you can be like \cite{handigol:asterix} and give each switch the ability to do useful things itself (they did load-balancing "as a network primitive", which is fairly cool).

why: \cite{mendonca:hetero} and \cite{dely:wmn}

\newpage
\subsection{Routing Algorithms}
\subsubsection{Traditional Mesh Routing}
discussion of what makes a good mesh routing protocol. mesh routing is inherently distributed so don't force packets through centralised bits and stuff like that.

most common non-sdn mesh routing protocols. traditional routing involves routing based on individual packets (common knowledge?).

major ones marius has mentioned: olsr \cite{rfc3626}, ospf \cite{rfc5340}

oblivious vs predictive routing? \cite{wellons:augmenting}, \cite{dai:dynamic}, \cite{wang:routing}, 

\subsubsection{Software-Defined Mesh Routing}
attempts to do mesh routing in sdn context. flow-based routing means routing based on flows (linked series of related packets eg all tcp traffic, all traffic from one mac address or to a particular ip subnet).

commonly seen as a solution to 

note that this is not "centralised" routing. once rules are installed packet forwarding happens at individual switches exactly as it always has, at line rate (right?). the controller can push an initial set of rules as soon as a switch connects to it if desired. depending on configuration (fail standalone mode or fail secure mode) these rules can remain in place if the controller connection is lost, or the switch can drop all packets. \cite{handigol:asterix} makes the distinction between "logically centralised" and "distributed through the network". so, fine to have centralised controller if you can talk to that. 

flow-based networking \cite[pp. 862--863]{cormen:algorithms} can be modelled as a multi-commodity flow problem

\newpage
\subsection{Protocols and Tools}
\subsubsection{OpenFlow}
spec? \cite{onf:switch140}. 

i believe (find a source, this was from a blog post or something) that the new version of the spec \cite{onf:switch140} has more support for experimental stuff and people had some comments about whether this was good or bad for open standards

openflow is for communicating between switches and controller. 

allows switch to be controlled by multiple controllers \cite{mckeown:openflow}

\subsubsection{Mininet}
talk about:

what mininet is and how it works with the containers and stuff \cite{handigol:mininet}

mininet benchmarks \cite{handigol:benchmarks}

can use pretend openflow-enabled switches in the simulations, like openvswitch (no idea how to cite this)

\subsubsection{POX}
There are a number of controller frameworks today which allow programmers to use familiar languages and development environments to send OpenFlow messages to switches in the network; selection in the first case is based on familiarity with the primary language used. One such controller framework, which uses Python, is POX \cite{onl:pox}, developed at Stanford concurrently with the related NOX (C++) framework.

POX is designed more for ease of research than speed and performance, NOX being more suited to the latter. This is acceptable if performance of the network is not bound by the performance of the controller, at least for initial development. Experiments to determine whether this assumption is reasonable can be performed as required.

\newpage
\section{Project Plan}
\subsection{Contribution}
problem: implement a controller to do optimal routing in a mesh network

assumptions: controller has topology and link capacity info, and a route to each switch in the network

constraints: want packets in a flow to arrive in order, so all packets within a flow. define flow in this context to mean between a single source/dest

solution: model as multi-commodity flow problem.

\subsection{Methodology}

as stated earlier the project involves comparing the performance of existing approaches to sdn for wmns, and delivering a controller in pox to do optimal routing, and compare this to the benchmarked performance.

things to do in order to achieve this:

overview of common approaches (research)

note common "features" of these approaches and what sort of topologies would best capture them. well, what sort of topologies would best allow us to differentiate between different approaches.

in addition to topologies: come up with range of network events to simulate as well. mininet allows simulation of stuff like link up/down, has good wireless stuff eg link slowly moving out of range.

do maths (at some point)

implement a working version of each selected approach

implement controller, note performance on various metrics, improve based on results

all of these steps including dates of assessment are summarised in Table \ref{table:schedule}

\subsection{Schedule}

\begin{table}[H]
	\begin{center}
		\begin{tabular}{@{}rllr@{}}
			\toprule
			& Task & Duration & Completion\\
			\midrule
			& Establish project definition and scope & 1 week & 6 March \\
			& Set up environment (Mininet,  POX) & 1 week & 14 March \\
			\emph{Assessment} & Project proposal & 2 weeks & 27 March \\
			& Set up test suite (topologies, network events) & 1 week & 4 April \\
			& Implement selection of existing designs & 1 week & 11 April \\
			& Model proposed design & 1 week & 18 April \\
			& Begin implementing proposed design & 2 weeks & 2 May \\
			& Benchmark new controller against existing & 1 week & 9 May \\
			\emph{Assessment} & Progress seminar & 2 weeks & 19-23 May \\
			\addlinespace
			& \emph{Coursework examinations/semester break} \\
			\addlinespace
			& Write up current progress in thesis report & 2 weeks & 8 Aug\\
			& Revise test suite as necessary & 2 weeks & 22 Aug\\
			& Iteratively develop/test new controller & 5 weeks & 26 Sept\\
			& Gather final benchmarking results & 2 weeks & 10 Oct \\
			\emph{Assessment} & Project demonstration & 2 weeks & 20-24 Oct \\
			& Respond to demonstration feedback & 1 week & 31 Oct \\
			\emph{Assessment} & Thesis report & 3 weeks & 10 Nov \\
			\bottomrule
		\end{tabular}
		\caption{Proposed schedule outlining estimated duration and completion dates}
		\label{table:schedule}
	\end{center}
\end{table}

\subsection{Risk Assessment}
\subsubsection{Occupational Health and Safety}
This project requires work which can be completed in low-risk computing laboratories, which are covered by general OHS laboratory rules.

\subsubsection{Project Risks and Response}
Table \ref{table:risks} identifies the potential risks to the project, listed in order of severity from 1 (least critical) to 5 (most critical). Mitigation strategies for each risk are listed in Table \ref{table:mitigation}.

\hspace{0.5cm}
\begin{table}[H]
	\begin{center}
		\begin{tabular}{@{}rlllr@{}}
			\toprule
			\# & Risk & Likelihood & Impact \\
			\midrule
			1 & Loss of working environment & low & low \\
			2 & Loss of research data & low & medium \\
			3 & Illness during thesis & medium & medium \\
			4 & Major scope changes & high & medium \\
			5 & Falling behind schedule & high & high \\
			\bottomrule
		\end{tabular}
		\caption{Likelihood and severity of potential risks to the project}
		\label{table:risks}
	\end{center}
\end{table}

\begin{table}[H]
	\begin{center}
		\begin{tabularx}{\textwidth}{p{.02\textwidth}X}
			\toprule
			\# & Risk: Action \\
			\midrule
			1 & Loss of working environment:
			maintain list of software versions in use along with install notes so environment can be quickly recreated. \\
			\addlinespace
			2 & Loss of research data:
			commit all raw data (reports, slides, code, test results) to remote git repository; back up working directory to Dropbox/EAIT fileserver. \\
			\addlinespace
			3 & Illness during thesis:
			inform supervisor as soon as practicable to discuss impact on relevant assessment; if necessary obtain medical certificate and request extension. \\
			\addlinespace
			4 & Major scope changes:
			discuss suitable direction with supervisor; determine what prior work can be integrated into new report; reassess project schedule. \\
			\addlinespace
			5 & Falling behind schedule:
			conduct weekly progress meetings with supervisor with deliverables; regularly check progress against original schedule \\
			\addlinespace
			\bottomrule
		\end{tabularx}
		\caption{Risk mitigation strategies for potential project risks}
		\label{table:mitigation}
	\end{center}
\end{table}

\newpage \bibliographystyle{abbrv}
\bibliography{bib}

\end{document}
